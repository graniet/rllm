[package]
name = "rllm"
version = "0.1.0"
edition = "2021"
description = "A Rust LLM crate for Chat and Completions with multiple backends"
license = "MIT"
authors = ["Tristan Granier <graniet75@gmail.com>"]
repository = "https://github.com/graniet/rllm"

[features]
default = []
openai = []
anthropic = []
ollama = []

[dependencies]
serde = { version = "1.0", features = ["derive"] }
reqwest = { version = "0.11", features = ["blocking", "json"] }
serde_json = "1.0"

[dev-dependencies]
